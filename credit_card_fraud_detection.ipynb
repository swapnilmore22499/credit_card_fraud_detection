{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1dfb8c",
   "metadata": {},
   "source": [
    "## Problem Statement:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9d7ff82",
   "metadata": {},
   "source": [
    "In the banking industry, credit card fraud detection using machine learning is not only a trend but a necessity for them to put proactive monitoring and fraud prevention mechanisms in place. Machine learning is helping these institutions to reduce time-consuming manual reviews, costly chargebacks and fees as well as denials of legitimate transactions.\n",
    "In this project we will detect fraudulent credit card transactions with the help of Machine learning models. We will analyse customer-level data that has been collected and analysed.\n",
    "\n",
    "the main objective of this project is detect fraudulent transactions with the help of credit card details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec93de",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b48235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327dbe9",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ee57e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "786e65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None # it will show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff848ff",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d755f3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c528c4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b1c7e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>1.772925e-15</td>\n",
       "      <td>9.289524e-16</td>\n",
       "      <td>-1.803266e-15</td>\n",
       "      <td>1.674888e-15</td>\n",
       "      <td>1.475621e-15</td>\n",
       "      <td>3.501098e-15</td>\n",
       "      <td>1.392460e-15</td>\n",
       "      <td>-7.466538e-16</td>\n",
       "      <td>4.258754e-16</td>\n",
       "      <td>9.019919e-16</td>\n",
       "      <td>5.126845e-16</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>1.020713e+00</td>\n",
       "      <td>9.992014e-01</td>\n",
       "      <td>9.952742e-01</td>\n",
       "      <td>9.585956e-01</td>\n",
       "      <td>9.153160e-01</td>\n",
       "      <td>8.762529e-01</td>\n",
       "      <td>8.493371e-01</td>\n",
       "      <td>8.381762e-01</td>\n",
       "      <td>8.140405e-01</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>-4.797473e+00</td>\n",
       "      <td>-1.868371e+01</td>\n",
       "      <td>-5.791881e+00</td>\n",
       "      <td>-1.921433e+01</td>\n",
       "      <td>-4.498945e+00</td>\n",
       "      <td>-1.412985e+01</td>\n",
       "      <td>-2.516280e+01</td>\n",
       "      <td>-9.498746e+00</td>\n",
       "      <td>-7.213527e+00</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>-7.624942e-01</td>\n",
       "      <td>-4.055715e-01</td>\n",
       "      <td>-6.485393e-01</td>\n",
       "      <td>-4.255740e-01</td>\n",
       "      <td>-5.828843e-01</td>\n",
       "      <td>-4.680368e-01</td>\n",
       "      <td>-4.837483e-01</td>\n",
       "      <td>-4.988498e-01</td>\n",
       "      <td>-4.562989e-01</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>-3.275735e-02</td>\n",
       "      <td>1.400326e-01</td>\n",
       "      <td>-1.356806e-02</td>\n",
       "      <td>5.060132e-02</td>\n",
       "      <td>4.807155e-02</td>\n",
       "      <td>6.641332e-02</td>\n",
       "      <td>-6.567575e-02</td>\n",
       "      <td>-3.636312e-03</td>\n",
       "      <td>3.734823e-03</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>7.395934e-01</td>\n",
       "      <td>6.182380e-01</td>\n",
       "      <td>6.625050e-01</td>\n",
       "      <td>4.931498e-01</td>\n",
       "      <td>6.488208e-01</td>\n",
       "      <td>5.232963e-01</td>\n",
       "      <td>3.996750e-01</td>\n",
       "      <td>5.008067e-01</td>\n",
       "      <td>4.589494e-01</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>1.201891e+01</td>\n",
       "      <td>7.848392e+00</td>\n",
       "      <td>7.126883e+00</td>\n",
       "      <td>1.052677e+01</td>\n",
       "      <td>8.877742e+00</td>\n",
       "      <td>1.731511e+01</td>\n",
       "      <td>9.253526e+00</td>\n",
       "      <td>5.041069e+00</td>\n",
       "      <td>5.591971e+00</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "                V10           V11           V12           V13           V14  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.772925e-15  9.289524e-16 -1.803266e-15  1.674888e-15  1.475621e-15   \n",
       "std    1.088850e+00  1.020713e+00  9.992014e-01  9.952742e-01  9.585956e-01   \n",
       "min   -2.458826e+01 -4.797473e+00 -1.868371e+01 -5.791881e+00 -1.921433e+01   \n",
       "25%   -5.354257e-01 -7.624942e-01 -4.055715e-01 -6.485393e-01 -4.255740e-01   \n",
       "50%   -9.291738e-02 -3.275735e-02  1.400326e-01 -1.356806e-02  5.060132e-02   \n",
       "75%    4.539234e-01  7.395934e-01  6.182380e-01  6.625050e-01  4.931498e-01   \n",
       "max    2.374514e+01  1.201891e+01  7.848392e+00  7.126883e+00  1.052677e+01   \n",
       "\n",
       "                V15           V16           V17           V18           V19  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   3.501098e-15  1.392460e-15 -7.466538e-16  4.258754e-16  9.019919e-16   \n",
       "std    9.153160e-01  8.762529e-01  8.493371e-01  8.381762e-01  8.140405e-01   \n",
       "min   -4.498945e+00 -1.412985e+01 -2.516280e+01 -9.498746e+00 -7.213527e+00   \n",
       "25%   -5.828843e-01 -4.680368e-01 -4.837483e-01 -4.988498e-01 -4.562989e-01   \n",
       "50%    4.807155e-02  6.641332e-02 -6.567575e-02 -3.636312e-03  3.734823e-03   \n",
       "75%    6.488208e-01  5.232963e-01  3.996750e-01  5.008067e-01  4.589494e-01   \n",
       "max    8.877742e+00  1.731511e+01  9.253526e+00  5.041069e+00  5.591971e+00   \n",
       "\n",
       "                V20           V21           V22           V23           V24  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   5.126845e-16  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min   -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%   -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%   -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "269707b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14a66823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows are >> 284807\n",
      "Number of columns are>> 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows are >>\",df.shape[0])\n",
    "print(\"Number of columns are>>\",df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14c51c",
   "metadata": {},
   "source": [
    "## Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f45b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ae710fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "df[\"Amount\"]=sc.fit_transform(pd.DataFrame(df[\"Amount\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c9346cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "accd6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"Time\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c16ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b11d5344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check our dataset contain duplicate values\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11753775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29805553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "943ee2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd366fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af66a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check whether our data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f450afae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1       473\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c24d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0fef0",
   "metadata": {},
   "source": [
    "### Training and testing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2e102d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"Class\",axis=1)\n",
    "y=df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77e26d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a516a2",
   "metadata": {},
   "source": [
    "### Handling imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24113ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bdad1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smt = SMOTE(k_neighbors=5,random_state=45)\n",
    "x_sampled,y_sampled=smt.fit_resample(x,y)\n",
    "y_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45f7968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    275190\n",
       "1    275190\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "358e0d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1          V2          V3         V4          V5          V6          V7          V8         V9         V10        V11        V12        V13        V14         V15        V16        V17        V18        V19        V20         V21        V22        V23        V24        V25        V26        V27        V28         Amount   \n",
       "-56.407510  -72.715728  -6.605265   16.491217   34.801666  -26.160506  -19.399981  -1.501300   6.967698   9.537780   3.089395   1.776452   3.732744  -2.530792    5.784514   3.903988  -1.929314   0.206699   2.805883  -12.360962  -6.266878  -1.272167   7.893082   0.767805   5.376595   0.163672  -8.358317   33.847808   4.451791    1\n",
       " 0.210065    3.673594   -5.939243   6.069659    1.357794   -2.333811   -1.008120    0.426847  -3.778337  -4.638134   5.195455  -5.874979  -2.496669  -10.541567   0.043704  -0.876309   0.328050   0.911202  -1.566508   0.347403    0.378945  -0.348357  -0.451519  -0.497239   1.047773   0.547369   0.555570   0.377787   -0.350447    1\n",
       " 0.210190    0.376752   -0.628059   1.610832    1.154689   -0.509063    0.277630   -0.092298  -0.880588   0.858676  -0.065022  -0.256592  -0.136804  -0.151135    0.056685  -0.226301   0.555460  -0.090705   1.443113   0.162963    0.053548   0.230794   0.224975   0.727468  -0.940203   1.612213  -0.074546   0.096378   -0.329432    1\n",
       " 0.210189    1.182290    0.320918   2.879797    1.418419   -0.485918    1.434163   -0.387686  -1.559430   1.077658  -1.519936  -0.951400  -0.674375   0.141278   -1.483136   0.416870  -0.827278  -0.314274  -1.754266  -0.208021    0.238386   0.826897  -0.357316  -0.012981   0.454867   0.221242  -0.268452  -0.318921   -0.323809    1\n",
       " 0.210179    1.089803   -1.957672  -0.433683    0.992292   -1.093528    0.990245    0.199385  -0.690934  -0.884654   0.731512   0.198398  -1.020869  -0.088691   -1.368814   0.171193   0.600599   0.510005  -0.088766  -0.302418    0.232839   0.568465  -0.002169   0.711447  -0.348031   0.493986  -0.167354  -0.055372   -0.260674    1\n",
       "                                                                                                                                                                                                                                                                                                                                         ..\n",
       "-1.673558   -1.368263    0.975668  -1.900789    2.129729    3.614421   -1.116419    1.081276  -0.747162   0.008210  -0.917064  -0.329076   0.185192  -0.592586   -0.240061  -0.819964  -0.634553   1.620631  -0.850185  -0.428966   -0.477222  -0.979069  -0.194489   1.015702   0.295645   0.352492   0.034362   0.075749    0.102472    1\n",
       "-1.673574    3.359726   -3.885016   2.704382   -1.984990   -2.728860   -3.450300    1.391066  -0.750002  -6.147363   4.380344  -8.239907   0.358676  -6.598172    0.311066  -3.063004  -4.194180  -1.206355  -0.185158   0.366676    0.458317  -0.552484   0.075773   0.462209  -0.044226   0.306312   0.534047   0.238698   -0.349231    1\n",
       "-1.673577    3.354635   -3.888617   2.685783   -1.965664   -2.688006   -3.454074    1.397930  -0.764230  -6.131050   4.420122  -8.195404   0.404094  -6.573929    0.275615  -3.053412  -4.241402  -1.188935  -0.155479   0.370232    0.459960  -0.547497   0.070226   0.425582  -0.038336   0.307724   0.533759   0.237436   -0.349231    1\n",
       "-1.673590    0.572325    0.621793  -1.932534   -0.431970   -0.923449   -0.322573    1.008947   0.577738  -1.931596   0.921290   0.935435  -1.730317   1.175463   -0.294248  -0.463194   0.218518  -0.031859  -0.110530  -0.578605    0.078727  -0.042385  -0.164784   0.181623  -0.084221  -1.047195  -0.165178  -0.118881   -0.349231    1\n",
       " 2.454930   -0.989065   -2.512114  -1.877104    0.081287   -0.831825   -0.240601   -0.467361  -1.949390   1.737065  -1.553888  -1.361226   0.249681   0.210405   -0.049820  -0.857286   0.362569  -0.126316   0.143420  -0.437697   -0.074210   0.247125  -0.037124  -0.075137   0.445896   0.102445  -0.056362  -0.079442   -0.321245    1\n",
       "Length: 550380, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7966d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_sampled,y_sampled,test_size=0.20,random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4052ec",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f4a26",
   "metadata": {},
   "source": [
    "### 1) logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4daca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import f1_score,recall_score,accuracy_score,precision_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bb30c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eee8130b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[214713   5556]\n",
      " [ 18579 201456]]\n",
      "********************\n",
      "accuracy 0.9451855990406628\n",
      "********************\n",
      "classificatio report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95    220269\n",
      "           1       0.97      0.92      0.94    220035\n",
      "\n",
      "    accuracy                           0.95    440304\n",
      "   macro avg       0.95      0.95      0.95    440304\n",
      "weighted avg       0.95      0.95      0.95    440304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "y_pred_train = log_model.predict(x_train)\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"confusion matrix\\n\",cnf_matrix)\n",
    "print(\"*\"*20)\n",
    "accuracy = accuracy_score(y_train,y_pred_train)\n",
    "print(\"accuracy\",accuracy)\n",
    "print(\"*\"*20)\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"classificatio report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80c89fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[53463  1458]\n",
      " [ 4685 50470]]\n",
      "********************\n",
      "accuracy 0.9441931029470547\n",
      "********************\n",
      "classificatio report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     54921\n",
      "           1       0.97      0.92      0.94     55155\n",
      "\n",
      "    accuracy                           0.94    110076\n",
      "   macro avg       0.95      0.94      0.94    110076\n",
      "weighted avg       0.95      0.94      0.94    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "y_pred = log_model.predict(x_test)\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"confusion matrix\\n\",cnf_matrix)\n",
    "print(\"*\"*20)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"accuracy\",accuracy)\n",
    "print(\"*\"*20)\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(\"classificatio report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56aa439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "147d2072",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3658a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a13c8",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "611eceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier()\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74283837",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b11aa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[220269      0]\n",
      " [     0 220035]]\n",
      "ACCURACY 100.0\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    220269\n",
      "           1       1.00      1.00      1.00    220035\n",
      "\n",
      "    accuracy                           1.00    440304\n",
      "   macro avg       1.00      1.00      1.00    440304\n",
      "weighted avg       1.00      1.00      1.00    440304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "y_pred_train = dt_clf.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "Accuracy = accuracy_score(y_train,y_pred_train)\n",
    "print(\"ACCURACY\",Accuracy*100)\n",
    "\n",
    "cls_report = classification_report(y_train,y_pred_train)\n",
    "print(\"CLASSIFICATION REPORT\\n\",cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2ba89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1de2c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[54775   146]\n",
      " [   47 55108]]\n",
      "ACCURACY 99.8246665939896\n",
      "CLASSIFICATION REPORT\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     54921\n",
      "           1       1.00      1.00      1.00     55155\n",
      "\n",
      "    accuracy                           1.00    110076\n",
      "   macro avg       1.00      1.00      1.00    110076\n",
      "weighted avg       1.00      1.00      1.00    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y_pred_test = dt_clf.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,y_pred_test)\n",
    "print(\"ACCURACY\",Accuracy*100)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred_test)\n",
    "print(\"CLASSIFICATION REPORT\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a210ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558d711a",
   "metadata": {},
   "source": [
    "### Hyper parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9003a137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: array([2, 3, 4, 5, 6, 7]),\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: array([2, 3, 4, 5, 6, 7]),\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([2, 3, 4, 5, 6, 7]),\n",
       "                                        'min_samples_leaf': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'min_samples_split': array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "hyper_para = {\"criterion\" :['gini',\"entropy\"],\n",
    "\"max_depth\":np.arange(2,8),\n",
    "\"min_samples_split\":np.arange(3,20),\n",
    "\"min_samples_leaf\":np.arange(3,15),\n",
    "}\n",
    "rscv_dt_clf = RandomizedSearchCV(dt_model,hyper_para,cv=5)\n",
    "rscv_dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcf02d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tuning=rscv_dt_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81c18566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "442e4268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=10)\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e40ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[215460   4809]\n",
      " [  7659 212376]]\n",
      "Accuracy 0.9982466659398961\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97    220269\n",
      "           1       0.98      0.97      0.97    220035\n",
      "\n",
      "    accuracy                           0.97    440304\n",
      "   macro avg       0.97      0.97      0.97    440304\n",
      "weighted avg       0.97      0.97      0.97    440304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "y_pred_train = dt_clf.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion matrix\\n\",cnf_matrix)\n",
    "\n",
    "Accuaracy = accuracy_score(y_train,y_pred_train)\n",
    "print(\"Accuracy\",Accuracy)\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"Classification report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727adbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85c79495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[53678  1243]\n",
      " [ 1954 53201]]\n",
      "Accuracy 0.9982466659398961\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     54921\n",
      "           1       0.98      0.96      0.97     55155\n",
      "\n",
      "    accuracy                           0.97    110076\n",
      "   macro avg       0.97      0.97      0.97    110076\n",
      "weighted avg       0.97      0.97      0.97    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "y_pred_test = dt_clf.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "print(\"Confusion matrix\\n\",cnf_matrix)\n",
    "\n",
    "Accuaracy = accuracy_score(y_test,y_pred_test)\n",
    "print(\"Accuracy\",Accuracy)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred_test)\n",
    "print(\"Classification report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83dac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d145b831",
   "metadata": {},
   "source": [
    "### Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "512ea3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7a07a",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2957ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf= RandomForestClassifier()\n",
    "rf_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "702465cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics\n",
      " [[220269      0]\n",
      " [     0 220035]]\n",
      "accuracy 100.0\n",
      "clf_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    220269\n",
      "           1       1.00      1.00      1.00    220035\n",
      "\n",
      "    accuracy                           1.00    440304\n",
      "   macro avg       1.00      1.00      1.00    440304\n",
      "weighted avg       1.00      1.00      1.00    440304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "y_pred_train = rf_clf.predict(x_train)\n",
    "\n",
    "cnf_metrics = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"confusion metrics\\n\",cnf_metrics)\n",
    "\n",
    "accuracy = accuracy_score(y_train,y_pred_train)\n",
    "print(\"accuracy\",accuracy*100)\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"clf_report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc8d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9ae1eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion metrics\n",
      " [[54901    20]\n",
      " [    0 55155]]\n",
      "accuracy 99.98183073512845\n",
      "clf_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     54921\n",
      "           1       1.00      1.00      1.00     55155\n",
      "\n",
      "    accuracy                           1.00    110076\n",
      "   macro avg       1.00      1.00      1.00    110076\n",
      "weighted avg       1.00      1.00      1.00    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "y_pred_test = rf_clf.predict(x_test)\n",
    "\n",
    "cnf_metrics = confusion_matrix(y_test,y_pred_test)\n",
    "print(\"confusion metrics\\n\",cnf_metrics)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred_test)\n",
    "print(\"accuracy\",accuracy*100)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred_test)\n",
    "print(\"clf_report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5116c99",
   "metadata": {},
   "source": [
    "### HyperParamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68ad4797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: array([4, 5, 6, 7, 8, 9]),\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        &#x27;n_estimators&#x27;: array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
       "                                        &#x27;oob_score&#x27;: [True],\n",
       "                                        &#x27;random_state&#x27;: [41, 42, 43, 44, 45]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: array([4, 5, 6, 7, 8, 9]),\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        &#x27;n_estimators&#x27;: array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
       "                                        &#x27;oob_score&#x27;: [True],\n",
       "                                        &#x27;random_state&#x27;: [41, 42, 43, 44, 45]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': array([4, 5, 6, 7, 8, 9]),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        'min_samples_split': array([3, 4, 5, 6, 7, 8, 9]),\n",
       "                                        'n_estimators': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
       "                                        'oob_score': [True],\n",
       "                                        'random_state': [41, 42, 43, 44, 45]})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamter = {\"n_estimators\":np.arange(10,20),\n",
    "\"criterion\":[\"gini\",\"entropy\"],\n",
    "\"max_depth\" :np.arange(4,10),\n",
    "\"min_samples_split\":np.arange(3,10),\n",
    "\"min_samples_leaf\":np.arange(3,10),\n",
    "\"max_features\":[\"sqrt\", \"log2\"],\n",
    "\"random_state\":[41,42,43,44,45],\n",
    "\"oob_score\":[True]}\n",
    "rdscv = RandomizedSearchCV(rf_clf,hyperparamter,cv=4)\n",
    "rdscv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b759666",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_tuning=rdscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a9b7808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=9, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
       "                       oob_score=True, random_state=44)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=9, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
       "                       oob_score=True, random_state=44)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=9, max_features='log2',\n",
       "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
       "                       oob_score=True, random_state=44)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0bcd243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf= RandomForestClassifier(criterion='entropy', max_depth=9, max_features='log2',\n",
    "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
    "                       oob_score=True, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f76577fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=9, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
       "                       oob_score=True, random_state=44)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=9, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
       "                       oob_score=True, random_state=44)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=9, max_features='log2',\n",
       "                       min_samples_leaf=6, min_samples_split=4, n_estimators=19,\n",
       "                       oob_score=True, random_state=44)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "250ae791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusioin Matrix\n",
      " [[219861    408]\n",
      " [  8044 211991]]\n",
      "Accuracy 98.08041716632145\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    220269\n",
      "           1       1.00      0.96      0.98    220035\n",
      "\n",
      "    accuracy                           0.98    440304\n",
      "   macro avg       0.98      0.98      0.98    440304\n",
      "weighted avg       0.98      0.98      0.98    440304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "y_pred_train = rf_clf.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusioin Matrix\\n\",cnf_matrix)\n",
    "\n",
    "Accuracy=accuracy_score(y_train,y_pred_train)\n",
    "print(\"Accuracy\",Accuracy*100)\n",
    "\n",
    "clf_report=classification_report(y_train,y_pred_train)\n",
    "print(\"Classification report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eed795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c87aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[54781   140]\n",
      " [ 2036 53119]]\n",
      "Accuracy 98.02318398197609\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     54921\n",
      "           1       1.00      0.96      0.98     55155\n",
      "\n",
      "    accuracy                           0.98    110076\n",
      "   macro avg       0.98      0.98      0.98    110076\n",
      "weighted avg       0.98      0.98      0.98    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y_pred_test = rf_clf.predict(x_test)\n",
    "\n",
    "cnf_matrix=confusion_matrix(y_test,y_pred_test)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "Accuracy=accuracy_score(y_test,y_pred_test)\n",
    "print(\"Accuracy\",Accuracy*100)\n",
    "\n",
    "clf_report=classification_report(y_test,y_pred_test)\n",
    "print(\"Classification report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179417a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "091565cd",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93f4ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ba7a995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf439bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "157e1afa",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "99e57574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[216609   3660]\n",
      " [  4927 215108]]\n",
      "accuarcy 98.04975653185072\n",
      "classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    220269\n",
      "           1       0.98      0.98      0.98    220035\n",
      "\n",
      "    accuracy                           0.98    440304\n",
      "   macro avg       0.98      0.98      0.98    440304\n",
      "weighted avg       0.98      0.98      0.98    440304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "y_pred_train = svc_model.predict(x_train)\n",
    "\n",
    "cnf_metrix = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"confusion matrix\\n\",cnf_metrix)\n",
    "\n",
    "accuracy = accuracy_score(y_train,y_pred_train)\n",
    "print(\"accuarcy\",accuracy*100)\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"classification report\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25264647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[53958   963]\n",
      " [ 1268 53887]]\n",
      "accuarcy 97.97321850357935\n",
      "classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     54921\n",
      "           1       0.98      0.98      0.98     55155\n",
      "\n",
      "    accuracy                           0.98    110076\n",
      "   macro avg       0.98      0.98      0.98    110076\n",
      "weighted avg       0.98      0.98      0.98    110076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing Data\n",
    "y_pred = svc_model.predict(x_test)\n",
    "\n",
    "cnf_metrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"confusion matrix\\n\",cnf_metrix)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"accuarcy\",accuracy*100)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(\"classification report\",clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12014a6",
   "metadata": {},
   "source": [
    "### Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae8d57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6f50027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier()\n",
    "ada_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1d15b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[215064   5205]\n",
      " [ 11295 208740]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    220269\n",
      "           1       0.98      0.95      0.96    220035\n",
      "\n",
      "    accuracy                           0.96    440304\n",
      "   macro avg       0.96      0.96      0.96    440304\n",
      "weighted avg       0.96      0.96      0.96    440304\n",
      "\n",
      "ACCURACY 96.2525891202442\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "y_pred_train = ada_clf.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"Classification Report\\n\",clf_report)\n",
    "\n",
    "Accuracy = accuracy_score(y_train,y_pred_train)\n",
    "print(\"ACCURACY\",Accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53058a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67d0e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[53555  1366]\n",
      " [ 2884 52271]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     54921\n",
      "           1       0.97      0.95      0.96     55155\n",
      "\n",
      "    accuracy                           0.96    110076\n",
      "   macro avg       0.96      0.96      0.96    110076\n",
      "weighted avg       0.96      0.96      0.96    110076\n",
      "\n",
      "ACCURACY 96.13903121479704\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y_pred_test =ada_clf.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred_test)\n",
    "print(\"Classification Report\\n\",clf_report)\n",
    "\n",
    "Accuracy = accuracy_score(y_test,y_pred_test)\n",
    "print(\"ACCURACY\",Accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ec62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "386f1417",
   "metadata": {},
   "source": [
    "### Lets see the accuracy we've got by the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b51e914a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logostic Regression</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision tree with Hyperparameter</td>\n",
       "      <td>99.82</td>\n",
       "      <td>99.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest with Hyperparameter</td>\n",
       "      <td>98.08</td>\n",
       "      <td>98.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>98.04</td>\n",
       "      <td>97.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adaboost classifier</td>\n",
       "      <td>96.25</td>\n",
       "      <td>96.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MODEL  Training Accuracy  Testing Accuracy\n",
       "0                Logostic Regression              94.51             94.41\n",
       "1                      Decision tree             100.00             99.82\n",
       "2  Decision tree with Hyperparameter              99.82             99.82\n",
       "3                      Random Forest             100.00             99.98\n",
       "4  Random Forest with Hyperparameter              98.08             98.02\n",
       "5                                SVM              98.04             97.97\n",
       "6                Adaboost classifier              96.25             96.13"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACCURACY_df = pd.DataFrame({\"MODEL\":[\"Logostic Regression\",\"Decision tree\",\"Decision tree with Hyperparameter\",\n",
    "                            \"Random Forest\",\"Random Forest with Hyperparameter\",\"SVM\",\n",
    "                            \"Adaboost classifier\"],\n",
    "                   \"Training Accuracy\":[94.51,100.0,99.82,100.0,98.08,98.04,96.25],\n",
    "                   \"Testing Accuracy\":[94.41,99.82,99.82,99.98,98.02,97.97,96.13],\n",
    "                   })\n",
    "ACCURACY_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bdba7ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='MODEL', ylabel='Testing Accuracy'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets see thye graphical representation of our models accuracy\n",
    "\n",
    "sns.barplot(ACCURACY_df[\"MODEL\"],ACCURACY_df[\"Testing Accuracy\"],capsize=50,linewidth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4f3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
